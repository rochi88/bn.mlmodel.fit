(window.webpackJsonp=window.webpackJsonp||[]).push([[35],{524:function(t,s,a){"use strict";a.r(s);var n=a(10),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"মডেল-পারফর্মেন্স-দ্বিতীয়-এবং-শেষ-পর্ব"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#মডেল-পারফর্মেন্স-দ্বিতীয়-এবং-শেষ-পর্ব"}},[t._v("#")]),t._v(" মডেল পারফর্মেন্স - দ্বিতীয় এবং শেষ পর্ব")]),t._v(" "),a("p",[t._v("আমরা মেশিন লার্নিংয়ের একদম শেষ পর্বে চলে এলাম। আগের পর্বেই মোটামুটি দেখেছিলাম মডেল ভাল পারফর্ম না করলে অথবা অন্য মডেল আদৌ ভাল পারফর্ম করছে কিনা সেটা জানার জন্য কীভাবে কাজ আগাতে হয়।")]),t._v(" "),a("h2",{attrs:{id:"যেসব-টপিক-আলোচনা-করা-হয়েছে-টিক-দেওয়া-এবং-যেসব-টপিক-নিয়ে-আলোচনা-করা-হয়-নাই-টিক-ছাড়া"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#যেসব-টপিক-আলোচনা-করা-হয়েছে-টিক-দেওয়া-এবং-যেসব-টপিক-নিয়ে-আলোচনা-করা-হয়-নাই-টিক-ছাড়া"}},[t._v("#")]),t._v(" যেসব টপিক আলোচনা করা হয়েছে (টিক দেওয়া) এবং যেসব টপিক নিয়ে আলোচনা করা হয় নাই (টিক ছাড়া)")]),t._v(" "),a("ul",{staticClass:"contains-task-list"},[a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" টেস্ট ডেটার মাধ্যমে মডেল এভালুয়েশন")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" রেজাল্ট ইন্টারপ্রিটেশন")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" অ্যাকুরেসি বাড়ানো")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" কনফিউশন ম্যাট্রিক্স")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" Recall")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" Precision")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" AUC (Area Under Curve)")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" ROC (Receiver Operating Characteristics) - Curve")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" ওভারফিটিং")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" মডেল হাইপারপ্যারামিটার")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" ওভারফিটিং মিনিমাইজেশন")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" K-Fold / N-Fold Cross-validation")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" Bias-Variance Trade Off")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" ভাল পারফর্মেন্সের জন্য পার্ফেকশন ছাড় দেওয়া")])]),t._v(" "),a("p",[t._v("আমরা এখনো এই ধাপে,")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://i.imgur.com/YglPD3U.png",alt:"performance_step"}})]),t._v(" "),a("h1",{attrs:{id:"মডেল-পারফর্মেন্স-রিভিশন-roc"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#মডেল-পারফর্মেন্স-রিভিশন-roc"}},[t._v("#")]),t._v(" মডেল পারফর্মেন্স রিভিশন - ROC")]),t._v(" "),a("p",[t._v("ROC বোঝার আগে অবশ্যই "),a("code",[t._v("Confusion Matrix")]),t._v(" সম্পর্কে জানতে হবে, না জানলে আগের পর্ব থেকে পড়ে নিন।")]),t._v(" "),a("p",[t._v("ROC স্পেসে ROC কার্ভ আঁকার জন্য X-axis এ FPR (False Positive Rate) ও Y-axis এ TPR (True Positive Rate) বসাতে হয়।")]),t._v(" "),a("p",[t._v("তারমানে কনফিউশন ম্যাট্রিক্স থেকে প্রাপ্ত TPR ও FPR রেট বসালে আমরা একটা পয়েন্ট পাব, এভাবে একই ডেটাসেটের উপর প্রয়োগকৃত যতগুলা মডেল নিয়ে আমরা কাজ করব সেগুলোর প্রতিটি থেকে একটি করে পয়েন্ট পাব।")]),t._v(" "),a("p",[t._v("এই পয়েন্টগুলো যোগ করে দিয়ে গ্রাফ আঁকলেই আপনি পেয়ে যাবেন আপনার আকাঙ্ক্ষিত ROC কার্ভ।")]),t._v(" "),a("p",[t._v("একটা পার্ফেক্ট ক্লাসিফায়ারের TPR হয় 1 এবং FPR হয় 0।")]),t._v(" "),a("p",[t._v("একটি উদাহরণ দিয়েই ROC বোঝা যায়।")]),t._v(" "),a("p",[t._v("একটা সিনারিও দেখা যাক,")]),t._v(" "),a("blockquote",[a("p",[t._v("আমি একটা ডায়বেটিস ডেটাসেট নিলাম, ডেটাসেট এ Observation আছে 1000 টা, আমি এটাকে 80%-20% এ ভাগ করলাম। তারমানে 80% ডেটা হল ট্রেইনিং ডেটা, 20% ডেটা হল টেস্টিং ডেটা।")])]),t._v(" "),a("blockquote",[a("p",[t._v("আবার ধরুন, 200 টা টেস্টিং ডেটার মধ্যে 100 টা হল Positive (মানে আউটপুট পজিটিভ আরও সহজভাবে বললে ওই ১০০ টা ডেটার আউটকাম হল ডায়বেটিস হয়েছে)। এবং 100 টা Negative।")])]),t._v(" "),a("blockquote",[a("p",[t._v("আমি চারটা মডেল তৈরি করলাম, এই মডেল চারটা আমি ট্রেইন করব ও তাদের পারফর্মেন্স টেস্ট করব। চারটা মডেল হল,")])]),t._v(" "),a("ul",[a("li",[t._v("Gaussian Naive Bayes Model")]),t._v(" "),a("li",[t._v("Logistic Regression Model")]),t._v(" "),a("li",[t._v("Random Forest Model")]),t._v(" "),a("li",[t._v("Artificial Neural Network Model")])]),t._v(" "),a("p",[t._v("আমরা এখনো Artificial Neural Network দেখি নাই এবং এটা সম্পর্কে না জানলেও সমস্যা নেই।")]),t._v(" "),a("p",[t._v("আমি আগের পর্বের মত করে প্রতিটা মডেলকে ট্রেইন করে তারপর তাদের Confusion Matrix বের করতে পারি, তাই না? ঠিক সেভাবেই আমি 80% ডেটাসেট দিয়ে মডেলগুলোকে শিখিয়ে পড়িয়ে মানুষ করব তারপর তাদের পারফর্মেন্স টেস্ট করার জন্য পড়া ধরব। (কনফিউশন ম্যাট্রিক্স বের করব)।")]),t._v(" "),a("p",[t._v("আরও মনে করতে থাকেন, প্রতিটি মডেলের Confusion Matrix ও পাশাপাশি তাদের TPR, FPR বের করলাম।")]),t._v(" "),a("h3",{attrs:{id:"gaussian-naive-bayes-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gaussian-naive-bayes-model"}},[t._v("#")]),t._v(" Gaussian Naive Bayes Model")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("TP = 63")]),t._v(" "),a("th",[t._v("FP = 28")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("FN = 37")]),t._v(" "),a("td",[t._v("TN = 72")])])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("TPR = 0.63\nFPR = 0.28\n")])])]),a("h3",{attrs:{id:"logistic-regression-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#logistic-regression-model"}},[t._v("#")]),t._v(" Logistic Regression Model")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("TP = 77")]),t._v(" "),a("th",[t._v("FP = 77")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("FN = 23")]),t._v(" "),a("td",[t._v("TN = 23")])])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("TPR = 0.77\nFPR = 0.77\n")])])]),a("h3",{attrs:{id:"random-forest-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#random-forest-model"}},[t._v("#")]),t._v(" Random Forest Model")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("TP = 24")]),t._v(" "),a("th",[t._v("FP = 88")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("FN = 76")]),t._v(" "),a("td",[t._v("TN = 12")])])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("TPR = 0.24\nFPR = 0.88\n")])])]),a("h3",{attrs:{id:"artificial-neural-network-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#artificial-neural-network-model"}},[t._v("#")]),t._v(" Artificial Neural Network Model")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("TP = 76")]),t._v(" "),a("th",[t._v("FP = 12")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("FN = 24")]),t._v(" "),a("td",[t._v("TN = 88")])])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("TPR = 0.76\nFPR = 0.12\n")])])]),a("p",[t._v("আমরা আগেই জেনেছি ROC Curve এর ক্ষেত্রে Y-axis এ থাকে TPR এবং X-axis এ থাকে FPR। তাহলে আমরা এই চারটা Coordinate সহজেই ROC Space এ বসাতে পারি।")]),t._v(" "),a("h4",{attrs:{id:"coordinate-গুলো"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#coordinate-গুলো"}},[t._v("#")]),t._v(" Coordinate গুলো")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("Coordinate -> Model (X, Y)\n--------------------------------------\nG point -> Gaussian Naive (0.28, 0.63)\nL point -> Logistic Regression (.77, .77)\nR point -> Random Forest (.88, .24)\nA point -> Artificial Neural Network (.76, .12)\n")])])]),a("p",[t._v("এই পয়েন্টগুলো আমরা এখন প্লট করব।")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# fpr, tpr")]),t._v("\nnaive_bayes "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.28")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.63")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlogistic "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.77")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.77")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrandom_forest "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.88")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.24")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nann "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.76")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# plotting")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("naive_bayes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" naive_bayes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Naive Bayes'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" facecolors"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'black'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edgecolors"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'orange'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("300")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logistic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" logistic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Logistic Regression'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" facecolors"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'orange'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edgecolors"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'orange'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("300")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("random_forest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_forest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Random Forest'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" facecolors"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'blue'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edgecolors"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'black'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("300")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ann"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ann"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Artificial Neural Network'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" facecolors"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'red'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edgecolors"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'black'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("300")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'k--'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'False Positive Rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'True Positive Rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Receiver operating characteristic example'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("legend"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loc"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lower center'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("img",{attrs:{src:"https://i.imgur.com/UhTzNYS.png",alt:"roc"}})]),t._v(" "),a("p",[t._v("উদাহরণটি উইকিপিডিয়া থেকে নেয়া, উইকিপিডিয়ার ROC কার্ভে অতিরিক্ত কিছু জিনিস পয়েন্ট আউট করে দেওয়া আছে,")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://upload.wikimedia.org/wikipedia/commons/3/36/ROC_space-2.png",alt:"roc_wiki"}})]),t._v(" "),a("p",[t._v("আমি এখানে প্রতিটি পয়েন্ট বোঝানোর জন্য আলাদা ভাবে স্ক্যাটার প্লট করেছি। আপনার যদি মডেল অনেকগুলো হয় কিংবা, একই মডেলের প্যারামিটার পরিবর্তনভিত্তিক পারফর্মেন্স যদি আপনি প্লট করেন তাহলে আপনার প্লট করা ROC কার্ভ হবে এইরকম।")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://upload.wikimedia.org/wikipedia/commons/6/6b/Roccurves.png",alt:"orig_roc"}})]),t._v(" "),a("p",[t._v("আমার এখানে মডেল মাত্র ৪ টা, তাই এখানে লাইন প্লট করলে বোঝা যাবে না তাই, স্ক্যাটার প্লট করা হল।")]),t._v(" "),a("h3",{attrs:{id:"roc-curve-ব্যাখ্যা"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#roc-curve-ব্যাখ্যা"}},[t._v("#")]),t._v(" ROC Curve ব্যাখ্যা")]),t._v(" "),a("p",[t._v("100% Accurate Model এর FPR = 0 এবং TPR = 1। এটাকে আইডিয়াল ধরে সহজেই বোঝা যাচ্ছে ANN মডেল হিসেবে সবেচেয়ে ভাল, তারপর Naive Bayes, তারপর Logistic Regression এবং সবার শেষে Random Forest পারফর্ম করেছে।")]),t._v(" "),a("p",[t._v("আগেই (এবং আবারো) বলে রাখি, সবসময় ANN > NB > LR > RF এইরকম হবে তা নয়, ডেটাসেট ও প্রবলেমের ধরণ অনুযায়ী এক এক মডেলের পারফর্মেন্স একেক রকম। আমি এখানে পুরো ব্যাপারটা কল্পনা করেছি।")]),t._v(" "),a("p",[t._v("মাঝখান দিয়ে যে ড্যাশড লাইন কোণাকুণি বরাবর গিয়েছে তাকে বলে Line of no-discrimination। পয়েন্ট যত এই লাইনের উপরে থাকবে তত ভাল এবং নিচে থাকলে ততটাই খারাপ।")]),t._v(" "),a("h2",{attrs:{id:"auc-বা-area-under-curve"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#auc-বা-area-under-curve"}},[t._v("#")]),t._v(" AUC বা Area Under Curve")]),t._v(" "),a("p",[t._v("উপরে একটা ROC Curve দেখছেন নিশ্চয়? সেখানে ROC কার্ভ যতটা Area কভার করে ততটাই ভাল। 100% Accurate Model এর AUC হল TPR * FPR বা পুরো গ্রাফের ক্ষেত্রফল।")]),t._v(" "),a("p",[t._v("AUC দিয়ে পারফর্মেন্স পরিমাপ করা নিয়ে অনেক প্রশ্ন উঠেছে বর্তমানে, সবাই কমবেশি ROC প্রেফার করে । তাই AUC নিয়ে কথা বাড়ালাম না।")]),t._v(" "),a("h2",{attrs:{id:"ওভারফিটিং"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ওভারফিটিং"}},[t._v("#")]),t._v(" ওভারফিটিং")]),t._v(" "),a("p",[t._v("আগেও বলা হয়েছিল, কোন কোন সময় মডেলের পারফর্মেন্স এতটাই ভাল হয় যে Training Data এর ক্ষেত্রে Accuracy Rate প্রায় 95-99% হয়। কিন্তু Testing Data তে প্রেডিক্ট করতে দিলে 40% Accuracy Rate ও হয় না।")]),t._v(" "),a("p",[t._v("প্রশ্ন হচ্ছে, এটা কেন হয়?")]),t._v(" "),a("p",[t._v("আসলে আমরা যে ডেটাসেট দিয়ে ট্রেইন করি, সেখানে আসল ডেটার পাশাপাশি Noise ও থাকে। অর্থাৎ, 100% Pure Dataset আপনি কখনোই পাবেন না।")]),t._v(" "),a("p",[t._v("একটা ক্লাসিক এক্সাম্পল হতে পারে, আমি কিছু ডেটাসেট জোগাড় করলাম, কয় ঘণ্টা পড়ি আর কয় ঘণ্টা ঘুমাই তার উপর কত মার্কস পাই। এখন আমি এই ডেটাসেট এর উপরে মডেল ট্রেইন করে প্রেডিক্ট করতে বসে যাই এবং যদি কোনভাবে দেখি, পড়া কমিয়ে ঘুমালে মার্কস বেশি আসছে, এবং সেটার উপর ভিত্তি করে আমি পরবর্তী পরীক্ষার আগে ঘুমায়ে কাটালাম কিন্তু পড়লাম না একটুও (কারণ আমার তৈরি A.I বলেছে ঘুমালে মার্কস বেশি পাওয়া যাবে)। তাতে ফলাফল কী আসবে সেটা বোঝাই যাচ্ছে।")]),t._v(" "),a("p",[t._v("তাহলে এই যে ভুলভাল প্রেডিকশন দিচ্ছে, তার কারণ কী? দুইটা কারণ, (১) পর্যাপ্ত পরিমাণ ডেটা নাই, (২) ডেটাসেট এ কলামের সংখ্যা (ভ্যারিয়েবল, এখানে যেমন কয় ঘণ্টা পড়ি আর কয় ঘণ্টা ঘুমাই) কম। মার্কস ভাল আসার অনেক কারণ থাকতে পারে, পরীক্ষা যদি MCQ হয় আর তাতে ঝড়ে বক দিয়ে ভাল পরিমাণ দাগিয়ে ফেললাম, অথবা প্রশ্ন অনেক সহজ হল ইত্যাদি। তাহলে এগুলোতো আমি ইনপুট এ না দিয়েই ট্রেইন করেছি, তাই মডেল স্বভাবতই সেই "),a("code",[t._v("?")]),t._v(" কারণ গুলো না জেনেই আমার দেওয়া ডেটাসেট এর সাথে নিজেকে এমন ভাবে খাপ খাওয়াবে তাতে Error সবচেয়ে কম থাকে।")]),t._v(" "),a("p",[t._v("মডেল ট্রেইন মানে হচ্ছে Error কমানো, আর Error কমানোর জন্য প্রতিটি মডেলের হাইপারপ্যারামিটার গুলো ম্যাথেমেটিক্যাল অ্যানালাইসিস অনুযায়ী সেট হয়। যে হাইপারপ্যারামিটার ব্যবহার করলে Error সবচেয়ে কম হবে সেটাই মডেল ব্যবহার করবে (এটাই স্বাভাবিক)। কিন্তু Error কম করতে গিয়ে যদি Model, ডেটাসেটের Noise এর সাথে খাপ খাইয়ে নেয় তাহলে যথেষ্ট ঝামেলা হবে।")]),t._v(" "),a("p",[t._v("ওভারফিটিং সম্পর্কে পরবর্তীতে আমরা আরও বিস্তারিত দেখব কয়েকটি ধাপে।")]),t._v(" "),a("h2",{attrs:{id:"ওভারফিটিং-কমানো"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ওভারফিটিং-কমানো"}},[t._v("#")]),t._v(" ওভারফিটিং কমানো")]),t._v(" "),a("p",[t._v("ওভারফিটিং কমানোর জন্য যেটা করা যায় সেটা হচ্ছে, ডেটা জোগাড় করা এবং কলামের সংখ্যা বাড়ানো। যতটা পিওর সম্ভব ততটা পিওর ডেটাসেট ও ভাল প্রেডিকশন রেজাল্ট দিতে পারে। এটাতো গেল ডেটাসেট এ কি করবেন। চাইলে অ্যালগরিদম টিউন করেও ভাল রেজাল্ট বের করা সম্ভব। আমরা একটা মেথড দেখব।")]),t._v(" "),a("h3",{attrs:{id:"regularization-regularization-hyperparameter"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#regularization-regularization-hyperparameter"}},[t._v("#")]),t._v(" Regularization & Regularization Hyperparameter")]),t._v(" "),a("p",[t._v("একটা অ্যালগরিদম কীভাবে শিখবে সেটা আমরা চাইলে কন্ট্রোল করতে পারি। মেশিন লার্নিং অ্যালগরিদম মানেই তার পিছনে কোন না কোন ম্যাথমেটিক্যাল মডেল কাজ করছে, তাই সেই ম্যাথমেটিক্যাল মডেলের লার্নিং মেকানিজম চাইলে কিছু নির্দিষ্ট প্যারামিটার দিয়ে কন্ট্রোল করা যায়।")]),t._v(" "),a("p",[t._v("ধরি কোন একটি মডেল আউটপুট বের করে এই সূত্র দিয়ে,")]),t._v(" "),a("section",[a("eqn",[a("span",{staticClass:"katex-display"},[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("Y")]),a("mo",[t._v("=")]),a("mi",[t._v("a")]),a("msup",[a("mi",[t._v("x")]),a("mn",[t._v("3")])],1),a("mo",[t._v("+")]),a("mi",[t._v("b")]),a("mi",[t._v("x")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("Y = ax^{3} + bx")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault",staticStyle:{"margin-right":"0.22222em"}},[t._v("Y")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),a("span",{staticClass:"mrel"},[t._v("=")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.9474379999999999em","vertical-align":"-0.08333em"}}),a("span",{staticClass:"mord mathdefault"},[t._v("a")]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathdefault"},[t._v("x")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8641079999999999em"}},[a("span",{staticStyle:{top:"-3.113em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight"},[t._v("3")])])])])])])])])]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),a("span",{staticClass:"mbin"},[t._v("+")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.69444em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault"},[t._v("b")]),a("span",{staticClass:"mord mathdefault"},[t._v("x")])])])])])])],1),a("p",[t._v("আমরা এর লার্নিং কন্ট্রোল করার জন্য, (x * lambda) অংশ রেজাল্ট থেকে বিয়োগ দিয়ে "),a("code",[t._v("Regularized Model")]),t._v(" তৈরি করতে পারি,")]),t._v(" "),a("section",[a("eqn",[a("span",{staticClass:"katex-display"},[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("Y")]),a("mo",[t._v("=")]),a("mi",[t._v("a")]),a("msup",[a("mi",[t._v("x")]),a("mn",[t._v("3")])],1),a("mo",[t._v("+")]),a("mi",[t._v("b")]),a("mi",[t._v("x")]),a("mo",[t._v("−")]),a("mi",[t._v("λ")]),a("mi",[t._v("x")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("Y = ax^{3} + bx - \\lambda x")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault",staticStyle:{"margin-right":"0.22222em"}},[t._v("Y")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),a("span",{staticClass:"mrel"},[t._v("=")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.9474379999999999em","vertical-align":"-0.08333em"}}),a("span",{staticClass:"mord mathdefault"},[t._v("a")]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathdefault"},[t._v("x")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8641079999999999em"}},[a("span",{staticStyle:{top:"-3.113em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight"},[t._v("3")])])])])])])])])]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),a("span",{staticClass:"mbin"},[t._v("+")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.77777em","vertical-align":"-0.08333em"}}),a("span",{staticClass:"mord mathdefault"},[t._v("b")]),a("span",{staticClass:"mord mathdefault"},[t._v("x")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),a("span",{staticClass:"mbin"},[t._v("−")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.69444em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault"},[t._v("λ")]),a("span",{staticClass:"mord mathdefault"},[t._v("x")])])])])])])],1),a("p",[t._v("এখানে, "),a("eq",[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("λ")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\lambda")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.69444em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault"},[t._v("λ")])])])])]),t._v(" ই হল Regularization Hyperparameter।")],1),t._v(" "),a("p",[t._v("লক্ষণীয়, "),a("eq",[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("Y")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("Y")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault",staticStyle:{"margin-right":"0.22222em"}},[t._v("Y")])])])])]),t._v(" এর মান আগের প্রেডিকশনের থেকে কিছুটা কম আসবে, তারমানে আমি এবার Training Dataset এই Accuracy আগের চেয়ে কম পাব। কিন্তু এটা ভাল! কারণ? কারণ হচ্ছে , এবার সে প্রতিটা ডেটাসেট মুখস্ত করছে না, কারণ Regularization Hyperparameter তাকে মুখস্ত করতে দিবে না, "),a("eq",[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("x")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("x")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault"},[t._v("x")])])])])]),t._v(" এর মান যত বাড়বে, তার প্রেডিক্টেড ভ্যালু ততটাই পেনাল্টি খাবে। একে আমরা তাই Penalized Machine Learning Model বলতে পারি।")],1),t._v(" "),a("p",[t._v("যখনই মডেলটা এরর কমানোর জন্য ডেটাসেট এর সাথে খাপ খাওয়াতে যাবে, ওমনি lambda তাকে পেনাল্টি দিয়ে দূরে সরিয়ে দেবে। আমাদের আল্টিমেট কাজ হবে এই lambda কে এমন ভাবে টিউন করা যাতে Testing Dataset এ অ্যাকুরেসি ভাল আসে। Training Dataset এ অ্যাকুরেসি গোল্লায় যাক 😛")]),t._v(" "),a("h1",{attrs:{id:"logistic-regression-মডেলে-regularization-hyperparameter-টিউনিংয়ের-মাধ্যমে-অ্যাকুরেসি-বাড়ানো"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#logistic-regression-মডেলে-regularization-hyperparameter-টিউনিংয়ের-মাধ্যমে-অ্যাকুরেসি-বাড়ানো"}},[t._v("#")]),t._v(" Logistic Regression মডেলে Regularization Hyperparameter টিউনিংয়ের মাধ্যমে অ্যাকুরেসি বাড়ানো")]),t._v(" "),a("p",[t._v("টপিকের টাইটেল একটু বড় হয়ে গেল। একটু আগে আমরা জানলাম, ম্যাথমেটিক্যাল মডেল হ্যাক করে আমরা Regularization এর মাধ্যমে মডেলের ওভারফিটিং কমাতে পারি। মডেল ভিত্তিক Regularization Hyperparameter বিভিন্ন হয়। সাইকিট লাইব্রেরিতে অলরেডি Logistic Regression এর মডেলের কোড করে দেওয়া আছে এবং তারা Regularization Hyperparameter চেঞ্জ করার জন্য সুবিধাজনক ইন্টারফেসও দিয়েছে।")]),t._v(" "),a("p",[t._v("আমাদের কাজ হবে, Regularization Hyperparameter এর মান পরিবর্তন করে প্রেডিকশন স্কোর সংগ্রহ করা। তারপর যে Hyperparameter Value তে প্রেডিকশনের অ্যাকুরেসি সর্বোচ্চ হবে সেটা স্টোর করে রাখা।")]),t._v(" "),a("p",[t._v("থিওরি দেখলাম, এবার প্র্যাক্টিক্যাল দেখার পালা। এখন আপনাকে অবশ্যই নোটবুক বের করে কোড লিখতে হবে।")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://i.imgur.com/7vs17wU.gif",alt:"code"}})]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear_model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LogisticRegression\n\nlr_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlr_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ravel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlr_predict_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# training metrics")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Accuracy : {0:.4f}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("accuracy_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Confusion Matrix"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("confusion_matrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Classification Report"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("classification_report"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"আউটপুট"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#আউটপুট"}},[t._v("#")]),t._v(" আউটপুট")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("Accuracy : 0.7446\nConfusion Matrix\n[[ 44  36]\n [ 23 128]]\n\nClassification Report\n             precision    recall  f1-score   support\n\n          1       0.66      0.55      0.60        80\n          0       0.78      0.85      0.81       151\n\navg / total       0.74      0.74      0.74       231\n")])])]),a("p",[t._v("এই কাজগুলো আমরা নাইভ বেয়েস মডেলের জন্য করেছিলাম। এখানে "),a("strong",[t._v("C")]),t._v(" হচ্ছে আমাদের সেই Regularization Hyperparameter, শুরুতে ধরে নিলাম "),a("eq",[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mn",[t._v("0.7")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("0.7")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.64444em","vertical-align":"0em"}}),a("span",{staticClass:"mord"},[t._v("0")]),a("span",{staticClass:"mord"},[t._v(".")]),a("span",{staticClass:"mord"},[t._v("7")])])])])]),t._v(", আমরা পরে এর বিভিন্ন মানের জন্য অ্যাকুরেসি চেক করব।")],1),t._v(" "),a("h2",{attrs:{id:"c-regularization-hyperparameter-এর-মান-নির্ণয়"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#c-regularization-hyperparameter-এর-মান-নির্ণয়"}},[t._v("#")]),t._v(" C (Regularization Hyperparameter) এর মান নির্ণয়")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("\nC_start "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("\nC_end "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("\nC_inc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("\n\nC_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" recall_scores "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nC_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" C_start\n\nbest_recall_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" C_end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    C_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C_val"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    lr_model_loop "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("C_val"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    lr_model_loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ravel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    lr_predict_loop_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_model_loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    recall_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_predict_loop_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    recall_scores"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("recall_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" best_recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        best_recall_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" recall_score\n        best_lr_predict_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_predict_loop_test\n\n    C_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" C_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" C_inc\n\nbest_score_C_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" C_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("recall_scores"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("best_recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1st max value of {0:.3f} occured at C={1:.3f}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("best_recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" best_score_C_val"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("matplotlib inline\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" recall_scores"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"C value"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"recall score"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("যেহেতু Regularization Hyperparameter C, আর আমি বিভিন্ন C এর মানের জন্য recall_scores দেখতে চাচ্ছি (recall_score যত বেশি তত ভাল), তাই C_start = 0.1 নিলাম, C_end = 5 নিলাম, আর লুপে C এর মান 0.1 করে বৃদ্ধি করলাম।")]),t._v(" "),a("p",[t._v("আর প্রতি C এর ভ্যালুর জন্য প্রেডিক্টেড ডেটাসেট দিয়ে অ্যাকুরেসি চেক করলাম, যখনই recall এর মান আগেরটার চেয়ে বেশি হবে তখনই "),a("code",[t._v("best_recall_score")]),t._v(" এ "),a("code",[t._v("recall_score")]),t._v(" অর্থাৎ বর্তমান স্কোর অ্যাসাইন হবে।")]),t._v(" "),a("p",[t._v("আগের বিষয়গুলো বুঝতে পারলে কোডটা কঠিন কিছু নয়।")]),t._v(" "),a("p",[t._v("C_values এবং recall_scores নামের দুইটা লিস্ট রাখলাম ভ্যালু স্টোরের জন্য")]),t._v(" "),a("h3",{attrs:{id:"আউটপুট-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#আউটপুট-2"}},[t._v("#")]),t._v(" আউটপুট")]),t._v(" "),a("p",[t._v("C এর মান বৃদ্ধির সাথে কীভাবে পারফর্মেন্স পরিবর্তন হচ্ছে তার গ্রাফ।")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://i.imgur.com/poHfxeM.png",alt:"regularization1"}})]),t._v(" "),a("p",[t._v("C এর মান যখন 2-3 এর মধ্যে তখন Recall Score সবচেয়ে বেশি, C এর মান 4-5 এবং 0-1 এর মধ্যে কম।")]),t._v(" "),a("h2",{attrs:{id:"class-weight-balanced-ও-c-পরিবর্তনের-সাথে-মডেল-পারফর্মেন্স"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#class-weight-balanced-ও-c-পরিবর্তনের-সাথে-মডেল-পারফর্মেন্স"}},[t._v("#")]),t._v(" "),a("code",[t._v("class_weight = 'balanced'")]),t._v(" ও C পরিবর্তনের সাথে মডেল পারফর্মেন্স")]),t._v(" "),a("p",[t._v("Regularization Hyperparameter একটাই হবে তার কোন কারণ নেই, একাধিক থাকতে পারে। একটু আগে আমরা C এর মান বের করেছিলাম। এখন আমরা আরেকটি প্যারামিটার (class_weight) কে "),a("code",[t._v("balanced")]),t._v(" দিয়ে দেখব পারফর্মেন্স কিরকম দিচ্ছে।")]),t._v(" "),a("p",[a("code",[t._v("class_weight = 'balanced'")]),t._v(" রেখে C এর মান পরিবর্তন করে পারফর্মেন্স বের করাই হবে মূল উদ্দেশ্য।")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("\nC_start "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("\nC_end "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("\nC_inc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("\n\nC_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" recall_scores "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nC_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" C_start\nbest_recall_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" C_end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    C_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C_val"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    lr_model_loop "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("C_val"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class_weight"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"balanced"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    lr_model_loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ravel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    lr_predict_loop_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_model_loop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    recall_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_predict_loop_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    recall_scores"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("recall_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" best_recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        best_recall_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" recall_score\n        best_lr_predict_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_predict_loop_test\n\n    C_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" C_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" C_inc\n\nbest_score_C_val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" C_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("recall_scores"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("best_recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1st max value of {0:.3f} occured at C={1:.3f}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("best_recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" best_score_C_val"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("matplotlib inline\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" recall_scores"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"C value"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"recall score"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"আউটপুট-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#আউটপুট-3"}},[t._v("#")]),t._v(" আউটপুট:")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://i.imgur.com/2v4Mb7y.png",alt:"class_weight"}})]),t._v(" "),a("p",[t._v("ক্লাস ওয়েট "),a("code",[t._v("balanced")]),t._v(" দেওয়াতে দেখা যাচ্ছে Recall Score বেড়ে 0.73+ হয়েছে, definitely what we were looking for!")]),t._v(" "),a("p",[a("strong",[t._v("কনফিউশন ম্যাট্রিক্স")])]),t._v(" "),a("p",[t._v("কোড:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear_model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LogisticRegression\nlr_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" class_weight"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"balanced"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" C"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("best_score_C_val"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlr_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ravel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlr_predict_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# training metrics")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Accuracy: {0:.4f}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("accuracy_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("confusion_matrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Classification Report"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("classification_report"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("recall_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"আউটপুট-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#আউটপুট-4"}},[t._v("#")]),t._v(" আউটপুট:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("Accuracy: 0.7143\n[[ 59  21]\n [ 45 106]]\n\nClassification Report\n             precision    recall  f1-score   support\n\n          1       0.57      0.74      0.64        80\n          0       0.83      0.70      0.76       151\n\navg / total       0.74      0.71      0.72       231\n\n0.7375\n")])])]),a("p",[t._v("Regularization এর মাধ্যমে এভাবে আমরা অ্যাকুরেসি বাড়াতে পারি (ওভারফিটিং কমিয়ে)।")]),t._v(" "),a("h2",{attrs:{id:"k-fold-n-fold-cross-validation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#k-fold-n-fold-cross-validation"}},[t._v("#")]),t._v(" K-Fold / N-Fold Cross-validation")]),t._v(" "),a("p",[t._v("ওভারফিটিং কমানোর আরেকটি ইফেক্টিভ অ্যালগরিদম হল K-Fold Cross-validation। নামটা অনেক কঠিন শোনালেও কাজ খুবই সহজ।")]),t._v(" "),a("p",[t._v("আমাদের ডায়বেটিস ডেটাসেট এ কিন্তু নেগেটিভ উত্তর বেশি (মানে ডায়বেটিস হয় নাই)। যেখানে ডেটাসেট এর ব্যালেন্স কম থাকবে সেসব ক্ষেত্রে K-Fold Cross-validation খুবই ভাল অ্যাকুরেসি দিতে সাহায্য করে।")]),t._v(" "),a("p",[t._v("K-Fold বা N-Fold Cross-validation একই জিনিস যখন k=N! বা K = Number of observation।")]),t._v(" "),a("p",[t._v("k-Fold Cross-validation এ যেটা করা হয়, সম্পূর্ণ ডেটাসেটকে k equal sized এ সাবস্যাম্পল করা হয়।")]),t._v(" "),a("p",[t._v("এবার এই k সংখ্যক সাবস্যাম্পল থেকে একটা একটা করে ডেটা নেয়া হয় টেস্টিং এর জন্য।")]),t._v(" "),a("p",[t._v("যেমন, আমার কাছে 25 টা অবসার্ভেশনের ডেটাসেট আছে, আমি এদেরকে ৫ টা গ্রুপে ভাগ করলাম।")]),t._v(" "),a("p",[t._v("তারমানে প্রতিগ্রুপে ডেটাসেট থাকল ৫ টা করে। এবার এই পাঁচটা গ্রুপের প্রথম গ্রুপ আমি Hold করলাম বাকিগুলো ট্রেইনিংয়ে দিলাম, Hold করা ডেটাসেট দিয়ে টেস্ট করলাম।")]),t._v(" "),a("p",[t._v("দ্বিতীয় Pass এ দ্বিতীয় গ্রুপ Hold করব (ট্রেনিংয়ে পাঠাব না), আর বাকিগুলো Training এ পাঠাব।")]),t._v(" "),a("p",[t._v("ঠিক একই ভাবে চতুর্থ এবং পঞ্চম Pass এ ওই পজিশনাল গ্রুপটি Hold করে বাকিটা পাঠাব ট্রেইনিংয়ে।")]),t._v(" "),a("p",[t._v("এভাবে 5 বার 5-Fold এ ট্রেইন করব। যেহেতু প্রতি গ্রুপে Observation 5 টা এবং গ্রুপ সংখ্যা ৫ টা তাই এর নাম হবে N-Fold Cross-validation।")]),t._v(" "),a("h3",{attrs:{id:"cross-validation-ব্যবহার-করে-মডেল-ট্রেইনিং-ও-টেস্টিং"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cross-validation-ব্যবহার-করে-মডেল-ট্রেইনিং-ও-টেস্টিং"}},[t._v("#")]),t._v(" Cross-validation ব্যবহার করে মডেল ট্রেইনিং ও টেস্টিং")]),t._v(" "),a("p",[t._v("ক্রস ভ্যালিডেশন এনাবলড মডেল সাইকিটে বানানোই আছে, যেকোন নরমাল মডেল এর সাথে CV লাগিয়ে দিলেই Cross-validation Enabled Model পেয়ে যাবেন।")]),t._v(" "),a("p",[t._v("যেমন, LogisticRegression এর Cross-validation Enabled মডেল হবে LogisticRegressionCV, এভাবে বাকিগুলোর জন্যও সত্য।")]),t._v(" "),a("p",[t._v("চলুন এটার পারফর্মেন্স দেখা যাক,")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear_model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LogisticRegressionCV\n\nlr_cv_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegressionCV"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_jobs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Cs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cv"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" refit"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class_weight"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"balanced"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# set number of jobs to -1 which uses all cores to parallelize")]),t._v("\nlr_cv_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ravel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nlr_cv_predict_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_cv_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# training metrics")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Accuracy: {0:.4f}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("accuracy_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_cv_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("confusion_matrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_cv_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Classification Report"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("classification_report"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_cv_predict_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"আউটপুট-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#আউটপুট-5"}},[t._v("#")]),t._v(" আউটপুট:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("Accuracy: 0.7100\n[[ 55  25]\n [ 42 109]]\n\nClassification Report\n             precision    recall  f1-score   support\n\n          1       0.57      0.69      0.62        80\n          0       0.81      0.72      0.76       151\n\navg / total       0.73      0.71      0.72       231\n")])])]),a("p",[t._v("10-Fold ক্রস ভ্যালিডেশনে পারফর্মেন্স খারাপ আসে নি!")]),t._v(" "),a("p",[t._v("অনেক বড় হয়ে গেল চ্যাপ্টারটা, তবুও Bias-Variance টা বাদ থেকে গেল। পরবর্তী অন্য কোন পর্বে আমরা দেখব Bias-Variance Trade-off কী জিনিস এবং এর ইম্প্যাক্ট কতখানি।")]),t._v(" "),a("h2",{attrs:{id:"scikit-learn-algorithm-cheat-sheet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scikit-learn-algorithm-cheat-sheet"}},[t._v("#")]),t._v(" Scikit-learn Algorithm Cheat Sheet")]),t._v(" "),a("p",[t._v("ডেটাসেট থেকে অ্যালগো সিলেকশনের উপরে সাইকিটের নিজস্ব একটা চিটশিট আছে। খুবই ইফেক্টিভ,")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://i.imgur.com/acn08NR.png",alt:"cheatsheet"}})]),t._v(" "),a("h2",{attrs:{id:"শেষ-পর্যন্ত-যেসব-টপিক-নিয়ে-আলোচনা-করা-হল"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#শেষ-পর্যন্ত-যেসব-টপিক-নিয়ে-আলোচনা-করা-হল"}},[t._v("#")]),t._v(" শেষ পর্যন্ত যেসব টপিক নিয়ে আলোচনা করা হল")]),t._v(" "),a("ul",{staticClass:"contains-task-list"},[a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" টেস্ট ডেটার মাধ্যমে মডেল এভালুয়েশন")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" রেজাল্ট ইন্টারপ্রিটেশন")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" অ্যাকুরেসি বাড়ানো")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" কনফিউশন ম্যাট্রিক্স")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" Recall")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" Precision")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" AUC (Area Under Curve)")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" ROC (Receiver Operating Characteristics) - Curve")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" ওভারফিটিং")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" মডেল হাইপারপ্যারামিটার")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" ওভারফিটিং মিনিমাইজেশন")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" K-Fold / N-Fold Cross-validation")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" Bias-Variance Trade Off")]),t._v(" "),a("li",{staticClass:"task-list-item"},[a("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" ভাল পারফর্মেন্সের জন্য পার্ফেকশন ছাড় দেওয়া")])]),t._v(" "),a("Disqus")],1)}),[],!1,null,null,null);s.default=e.exports}}]);